{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547728f2",
   "metadata": {},
   "source": [
    "# ASSIGNMENT-1\n",
    "WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6ecf5",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3720c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>\n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7174165",
   "metadata": {},
   "source": [
    "# 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating. c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53909f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n",
      "   Position                Team Matches Points Rating\n",
      "0         1      Australia\\nAUS      23  2,714    118\n",
      "1         2       Pakistan\\nPAK      20  2,316    116\n",
      "2         3          India\\nIND      36  4,081    113\n",
      "3         4     New Zealand\\nNZ      27  2,806    104\n",
      "4         5        England\\nENG      24  2,426    101\n",
      "5         6    South Africa\\nSA      19  1,910    101\n",
      "6         7     Bangladesh\\nBAN      28  2,661     95\n",
      "7         8    Afghanistan\\nAFG      16  1,404     88\n",
      "8         9       Sri Lanka\\nSL      32  2,794     87\n",
      "9        10     West Indies\\nWI      38  2,582     68\n",
      "10       11       Zimbabwe\\nZIM      30  1,641     55\n",
      "11       12       Scotland\\nSCO      33  1,662     50\n",
      "12       13        Ireland\\nIRE      24  1,052     44\n",
      "13       14    Netherlands\\nNED      28  1,044     37\n",
      "14       15          Nepal\\nNEP      40  1,396     35\n",
      "15       16        Namibia\\nNAM      28    813     29\n",
      "16       17  United States\\nUSA      31    808     26\n",
      "17       18           Oman\\nOMA      24    525     22\n",
      "18       19            UAE\\nUAE      41    617     15\n",
      "\n",
      "Top 10 ODI Batsmen:\n",
      "                                             Position                Batsman  \\\n",
      "0                1\\n                        \\n\\n\\n(0)             Babar Azam   \n",
      "1        2\\n                                \\n\\n\\n(0)  Rassie van der Dussen   \n",
      "2        3\\n                                \\n\\n\\n(0)           Fakhar Zaman   \n",
      "3        4\\n                                \\n\\n\\n(0)            Imam-ul-Haq   \n",
      "4   5\\n                                \\n\\n\\n\\n\\n(...           Shubman Gill   \n",
      "..                                                ...                    ...   \n",
      "95      96\\n                                \\n\\n\\n(0)          Dasun Shanaka   \n",
      "96      97\\n                                \\n\\n\\n(0)       Avishka Fernando   \n",
      "97      98\\n                                \\n\\n\\n(0)              Ryan Burl   \n",
      "98      99\\n                                \\n\\n\\n(0)             Finn Allen   \n",
      "99     100\\n                                \\n\\n\\n(0)      Wanindu Hasaranga   \n",
      "\n",
      "   Team Rating              Career Best Rating  \n",
      "0   PAK    886   898 v West Indies, 10/06/2022  \n",
      "1    SA    777       796 v England, 19/07/2022  \n",
      "2   PAK    755   784 v New Zealand, 29/04/2023  \n",
      "3   PAK    745   815 v West Indies, 12/06/2022  \n",
      "4   IND    743   743 v West Indies, 01/08/2023  \n",
      "..  ...    ...                             ...  \n",
      "95   SL    440         506 v India, 10/01/2023  \n",
      "96   SL    439  591 v South Africa, 02/09/2021  \n",
      "97  ZIM    437      437 v Scotland, 04/07/2023  \n",
      "98   NZ    434      500 v Pakistan, 09/01/2023  \n",
      "99   SL    433         433 v India, 12/01/2023  \n",
      "\n",
      "[100 rows x 5 columns]\n",
      "\n",
      "Top 10 ODI Bowlers:\n",
      "                                             Position           Bowler Team  \\\n",
      "0                1\\n                        \\n\\n\\n(0)   Josh Hazlewood  AUS   \n",
      "1        2\\n                                \\n\\n\\n(0)   Mitchell Starc  AUS   \n",
      "2        3\\n                                \\n\\n\\n(0)      Rashid Khan  AFG   \n",
      "3        4\\n                                \\n\\n\\n(0)   Mohammed Siraj  IND   \n",
      "4        5\\n                                \\n\\n\\n(0)       Matt Henry   NZ   \n",
      "..                                                ...              ...  ...   \n",
      "95  96\\n                                \\n\\n\\n\\n\\n...    Henry Shipley   NZ   \n",
      "96  97\\n                                \\n\\n\\n\\n\\n...    Kasun Rajitha   SL   \n",
      "97      98\\n                                \\n\\n\\n(0)  Lalit Rajbanshi  NEP   \n",
      "98  99\\n                                \\n\\n\\n\\n\\n...   Ebadot Hossain  BAN   \n",
      "99  =\\n                                \\n\\n\\n\\n\\n\\...      Hamza Tahir  SCO   \n",
      "\n",
      "   Rating             Career Best Rating  \n",
      "0     705      733 v England, 26/01/2018  \n",
      "1     686  783 v New Zealand, 29/03/2015  \n",
      "2     682     806 v Pakistan, 21/09/2018  \n",
      "3     670  736 v New Zealand, 21/01/2023  \n",
      "4     667   691 v Bangladesh, 26/03/2021  \n",
      "..    ...                            ...  \n",
      "95    400     400 v Pakistan, 07/05/2023  \n",
      "96    395     411 v Scotland, 27/06/2023  \n",
      "97    388  397 v West Indies, 22/06/2023  \n",
      "98    385  389 v Afghanistan, 08/07/2023  \n",
      "99    385        484 v Nepal, 17/07/2022  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape and create a data frame\n",
    "def scrape_and_create_dataframe(url, columns):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        data = []\n",
    "\n",
    "        # Scrape data from the table\n",
    "        table = soup.find('table', class_='table')\n",
    "        rows = table.find_all('tr')[1:]  # Skip header row\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            record = [col.text.strip() for col in cols]\n",
    "            data.append(record)\n",
    "\n",
    "        # Create a data frame\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Scrape and create data frames for top 10 ODI teams, batsmen, and bowlers\n",
    "teams_url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "batsmen_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "bowlers_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "\n",
    "team_columns = [\"Position\", \"Team\", \"Matches\", \"Points\", \"Rating\"]\n",
    "batsmen_columns = [\"Position\", \"Batsman\", \"Team\", \"Rating\", \"Career Best Rating\"]\n",
    "bowlers_columns = [\"Position\", \"Bowler\", \"Team\", \"Rating\", \"Career Best Rating\"]\n",
    "\n",
    "top_10_teams_df = scrape_and_create_dataframe(teams_url, team_columns)\n",
    "top_10_batsmen_df = scrape_and_create_dataframe(batsmen_url, batsmen_columns)\n",
    "top_10_bowlers_df = scrape_and_create_dataframe(bowlers_url, bowlers_columns)\n",
    "\n",
    "# Display the data frames\n",
    "print(\"Top 10 ODI Teams:\")\n",
    "print(top_10_teams_df)\n",
    "\n",
    "print(\"\\nTop 10 ODI Batsmen:\")\n",
    "print(top_10_batsmen_df)\n",
    "\n",
    "print(\"\\nTop 10 ODI Bowlers:\")\n",
    "print(top_10_bowlers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ee78a",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating. c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4522fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n",
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      26  4,290    165\n",
      "1      England\\nENG      31  3,875    125\n",
      "2  South Africa\\nSA      26  3,098    119\n",
      "3        India\\nIND      30  3,039    101\n",
      "4   New Zealand\\nNZ      28  2,688     96\n",
      "5   West Indies\\nWI      29  2,743     95\n",
      "6   Bangladesh\\nBAN      17  1,284     76\n",
      "7     Sri Lanka\\nSL      12    820     68\n",
      "8     Thailand\\nTHA      13    883     68\n",
      "9     Pakistan\\nPAK      27  1,678     62\n",
      "\n",
      "Top 10 Women's ODI Batting Players:\n",
      "                 Player Team                         Rating\n",
      "0  Natalie Sciver-Brunt  ENG    803 v Australia, 18/07/2023\n",
      "1   Chamari Athapaththu   SL  758 v New Zealand, 03/07/2023\n",
      "2           Beth Mooney  AUS      776 v England, 12/07/2023\n",
      "3       Laura Wolvaardt   SA    741 v Australia, 22/03/2022\n",
      "4       Smriti Mandhana  IND      797 v England, 28/02/2019\n",
      "5          Alyssa Healy  AUS      785 v England, 03/04/2022\n",
      "6      Harmanpreet Kaur  IND      731 v England, 21/09/2022\n",
      "7          Ellyse Perry  AUS  766 v West Indies, 11/09/2019\n",
      "8           Meg Lanning  AUS  834 v New Zealand, 24/02/2016\n",
      "9       Stafanie Taylor   WI     766 v Pakistan, 07/07/2021\n",
      "\n",
      "Top 10 Women's ODI All-Rounders:\n",
      "                 Player Team                          Rating\n",
      "0  Natalie Sciver-Brunt  ENG     421 v Australia, 18/07/2023\n",
      "1      Ashleigh Gardner  AUS       389 v Ireland, 28/07/2023\n",
      "2       Hayley Matthews   WI       392 v Ireland, 26/06/2023\n",
      "3        Marizanne Kapp   SA   419 v West Indies, 10/09/2021\n",
      "4          Ellyse Perry  AUS   548 v West Indies, 11/09/2019\n",
      "5           Amelia Kerr   NZ   356 v West Indies, 25/09/2022\n",
      "6         Deepti Sharma  IND  397 v South Africa, 09/10/2019\n",
      "7         Jess Jonassen  AUS   308 v West Indies, 11/09/2019\n",
      "8         Sophie Devine   NZ     305 v Australia, 05/10/2020\n",
      "9              Nida Dar  PAK     232 v Australia, 21/01/2023\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape data for a given URL\n",
    "def scrape_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data from {url}\")\n",
    "\n",
    "# Function to create a dataframe from the scraped data\n",
    "def create_dataframe(data, columns):\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Scrape and create dataframe for Top 10 ODI teams\n",
    "def scrape_top_10_teams():\n",
    "    url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "    content = scrape_data(url)\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    teams = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    rating = []\n",
    "    \n",
    "    table = soup.find(\"table\", class_=\"table\")\n",
    "    rows = table.find_all(\"tr\")[1:11]  # Exclude header row and get top 10 teams\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        teams.append(cols[1].text.strip())\n",
    "        matches.append(cols[2].text.strip())\n",
    "        points.append(cols[3].text.strip())\n",
    "        rating.append(cols[4].text.strip())\n",
    "    \n",
    "    data = {\n",
    "        \"Team\": teams,\n",
    "        \"Matches\": matches,\n",
    "        \"Points\": points,\n",
    "        \"Rating\": rating\n",
    "    }\n",
    "    \n",
    "    df = create_dataframe(data, columns=[\"Team\", \"Matches\", \"Points\", \"Rating\"])\n",
    "    return df\n",
    "\n",
    "# Scrape and create dataframe for Top 10 women's ODI batting players\n",
    "def scrape_top_10_batting_players():\n",
    "    url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "    content = scrape_data(url)\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    players = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "    \n",
    "    table = soup.find(\"table\", class_=\"table\")\n",
    "    rows = table.find_all(\"tr\")[1:11]  # Exclude header row and get top 10 players\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        players.append(cols[1].text.strip())\n",
    "        teams.append(cols[2].text.strip())\n",
    "        ratings.append(cols[4].text.strip())\n",
    "    \n",
    "    data = {\n",
    "        \"Player\": players,\n",
    "        \"Team\": teams,\n",
    "        \"Rating\": ratings\n",
    "    }\n",
    "    \n",
    "    df = create_dataframe(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "    return df\n",
    "\n",
    "# Scrape and create dataframe for Top 10 women's ODI all-rounders\n",
    "def scrape_top_10_allrounders():\n",
    "    url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "    content = scrape_data(url)\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    players = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "    \n",
    "    table = soup.find(\"table\", class_=\"table\")\n",
    "    rows = table.find_all(\"tr\")[1:11]  # Exclude header row and get top 10 players\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        players.append(cols[1].text.strip())\n",
    "        teams.append(cols[2].text.strip())\n",
    "        ratings.append(cols[4].text.strip())\n",
    "    \n",
    "    data = {\n",
    "        \"Player\": players,\n",
    "        \"Team\": teams,\n",
    "        \"Rating\": ratings\n",
    "    }\n",
    "    \n",
    "    df = create_dataframe(data, columns=[\"Player\", \"Team\", \"Rating\"])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    top_10_teams_df = scrape_top_10_teams()\n",
    "    top_10_batting_players_df = scrape_top_10_batting_players()\n",
    "    top_10_allrounders_df = scrape_top_10_allrounders()\n",
    "    \n",
    "    print(\"Top 10 ODI Teams:\")\n",
    "    print(top_10_teams_df)\n",
    "    \n",
    "    print(\"\\nTop 10 Women's ODI Batting Players:\")\n",
    "    print(top_10_batting_players_df)\n",
    "    \n",
    "    print(\"\\nTop 10 Women's ODI All-Rounders:\")\n",
    "    print(top_10_allrounders_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751e0c5",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data framei) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32475c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Headline, Time, News Link]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    news_list = soup.find_all('div', class_='Card-titleContainer')\n",
    "\n",
    "    headlines = []\n",
    "    times = []\n",
    "    news_links = []\n",
    "\n",
    "    for news in news_list:\n",
    "        headline_elem = news.find('a', class_='Card-titleLink')\n",
    "        time_elem = news.find('time')\n",
    "        link_elem = news.find('a', class_='Card-titleLink')\n",
    "\n",
    "        if headline_elem and time_elem and link_elem:\n",
    "            headline = headline_elem.text\n",
    "            time = time_elem.text\n",
    "            link = link_elem['href']\n",
    "\n",
    "            headlines.append(headline)\n",
    "            times.append(time)\n",
    "            news_links.append(link)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    news_data = {\n",
    "        'Headline': headlines,\n",
    "        'Time': times,\n",
    "        'News Link': news_links\n",
    "    }\n",
    "    df = pd.DataFrame(news_data)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1086926",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data framei) Paper Title ii) Authors iii) Published Date iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e780def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the most downloaded articles page\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "# Find all the article details\n",
    "articles = soup.find_all(\"div\", class_=\"pod-listing-header\")\n",
    "\n",
    "# Initialize empty lists to store the scraped data\n",
    "titles = []\n",
    "authors = []\n",
    "published_dates = []\n",
    "paper_urls = []\n",
    "\n",
    "# Loop through each article and extract the required details\n",
    "for article in articles:\n",
    "    # Extract paper title\n",
    "    title = article.find(\"h2\").text.strip()\n",
    "    titles.append(title)\n",
    "    \n",
    "    # Extract authors\n",
    "    author = article.find(\"div\", class_=\"text-s\").text.strip()\n",
    "    authors.append(author)\n",
    "    \n",
    "    # Extract published date\n",
    "    published_date = article.find(\"span\", class_=\"text-xs\").text.strip()\n",
    "    published_dates.append(published_date)\n",
    "    \n",
    "    # Extract paper URL\n",
    "    paper_url = \"https://www.journals.elsevier.com\" + article.find(\"a\")[\"href\"]\n",
    "    paper_urls.append(paper_url)\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    \"Paper Title\": titles,\n",
    "    \"Authors\": authors,\n",
    "    \"Published Date\": published_dates,\n",
    "    \"Paper URL\": paper_urls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ddb95",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned details from dineout.co.inand make data framei) Restaurant name\n",
    "ii) Cuisine iii) Location iv) Ratings v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73174af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Restaurant Name, Cuisine, Location, Ratings, Image URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the dineout.co.in page you want to scrape\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Lists to store scraped data\n",
    "restaurant_names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "# Find all restaurant containers\n",
    "restaurant_containers = soup.find_all('div', class_='restnt-info-section')\n",
    "\n",
    "# Loop through each restaurant container\n",
    "for container in restaurant_containers:\n",
    "    # Restaurant Name\n",
    "    name = container.find('div', class_='restnt-name').text.strip()\n",
    "    restaurant_names.append(name)\n",
    "    \n",
    "    # Cuisine\n",
    "    cuisine = container.find('div', class_='restnt-cuisine').text.strip()\n",
    "    cuisines.append(cuisine)\n",
    "    \n",
    "    # Location\n",
    "    location = container.find('div', class_='restnt-loc').text.strip()\n",
    "    locations.append(location)\n",
    "    \n",
    "    # Ratings\n",
    "    rating = container.find('div', class_='restnt-rating').text.strip()\n",
    "    ratings.append(rating)\n",
    "    \n",
    "    # Image URL\n",
    "    image = container.find('img')['src']\n",
    "    image_urls.append(image)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Restaurant Name': restaurant_names,\n",
    "    'Cuisine': cuisines,\n",
    "    'Location': locations,\n",
    "    'Ratings': ratings,\n",
    "    'Image URL': image_urls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
